[{"source": "https://blog.roboflow.com", "title": "ImageNet contains naturally occurring NeuralHash collisions", "description": "NeuralHash is the perceptual hashing model that back's Apple's new CSAM (child sexual abuse material) reporting mechanism. It's an algorithm that takes an image as input and returns a 96-bit unique identifier (a hash) that should match for two images that are \"the same\" (besides some minor perturbations like JPEG", "link": "https://blog.roboflow.com/nerualhash-collision/", "date_published": "2021-08-20 12:15:24.402308+00:00", "persistent": true, "user": "Thomas Pain", "language": "en"}]